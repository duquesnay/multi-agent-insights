# Metrics Service Usage Guide

## Quick Start

```python
from common.metrics_service import extract_delegation_metrics

# Extract metrics from any delegation format
delegation = {...}  # From any data source
metrics = extract_delegation_metrics(delegation)

# Access standardized fields
print(f"Agent: {metrics['agent_type']}")
print(f"Tokens: {metrics['input_tokens']} in, {metrics['output_tokens']} out")
print(f"Amplification: {metrics['amplification_ratio']:.2f}x")
print(f"Cost: ${metrics['cost_usd']:.4f}")
```

## Core Functions

### 1. Extract Delegation Metrics

```python
from common.metrics_service import extract_delegation_metrics

metrics = extract_delegation_metrics(delegation)
```

**Handles multiple formats**:
- Raw delegations from `delegation_raw.jsonl`
- Enriched delegations from `enriched_sessions_v8.json`
- Session delegations from `extract_all_sessions.py`

**Returns**:
```python
{
    'agent_type': str or None,
    'input_tokens': int,
    'output_tokens': int,
    'cache_read_tokens': int,
    'cache_write_tokens': int,
    'total_tokens': int,
    'amplification_ratio': float,
    'cache_hit_rate': float,
    'cost_usd': float,
    'timestamp': str or None
}
```

### 2. Extract Session Metrics

```python
from common.metrics_service import extract_session_metrics

session_metrics = extract_session_metrics(session)
```

**Input**: Session dict with `delegations` list

**Returns**:
```python
{
    'session_id': str,
    'delegation_count': int,
    'total_input_tokens': int,
    'total_output_tokens': int,
    'total_cache_read_tokens': int,
    'total_cache_write_tokens': int,
    'total_tokens': int,
    'total_cost_usd': float,
    'avg_amplification_ratio': float,
    'avg_cache_hit_rate': float,
    'agents_used': List[str],
    'agent_counts': Dict[str, int]
}
```

### 3. Calculate Token Totals

```python
from common.metrics_service import calculate_token_totals

totals = calculate_token_totals(delegations)
```

**Input**: List of delegation dicts

**Returns**:
```python
{
    'total_delegations': int,
    'total_input_tokens': int,
    'total_output_tokens': int,
    'total_cache_read_tokens': int,
    'total_cache_write_tokens': int,
    'total_tokens': int,
    'total_cost_usd': float,
    'global_amplification_ratio': float,
    'global_cache_efficiency': float
}
```

### 4. Calculate Cost

```python
from common.metrics_service import calculate_cost

cost = calculate_cost({
    'input_tokens': 1000,
    'output_tokens': 2000,
    'cache_read_tokens': 500,
    'cache_write_tokens': 100
})
```

**Returns**: Cost in USD (float)

### 5. Validate Metrics

```python
from common.metrics_service import validate_metrics

is_valid = validate_metrics(metrics, context="session-123")
```

**Checks**:
- Required fields present
- Numeric types
- Non-negative values
- Reasonable ranges for ratios

**Returns**: True if valid, False otherwise (logs warnings)

## Common Patterns

### Analyzing All Delegations

```python
from common.data_repository import load_delegations
from common.metrics_service import extract_delegation_metrics

delegations = load_delegations(source='raw')

for delegation in delegations:
    metrics = extract_delegation_metrics(delegation)
    print(f"{metrics['agent_type']}: {metrics['output_tokens']} tokens")
```

### Grouping by Agent

```python
from collections import defaultdict
from common.metrics_service import extract_delegation_metrics

agent_stats = defaultdict(lambda: {
    'count': 0,
    'total_output': 0
})

for delegation in delegations:
    metrics = extract_delegation_metrics(delegation)
    agent = metrics['agent_type']

    agent_stats[agent]['count'] += 1
    agent_stats[agent]['total_output'] += metrics['output_tokens']
```

### Session-Level Analysis

```python
from common.metrics_service import extract_session_metrics

for session in sessions:
    session_metrics = extract_session_metrics(session)

    print(f"Session: {session_metrics['session_id']}")
    print(f"  Delegations: {session_metrics['delegation_count']}")
    print(f"  Cost: ${session_metrics['total_cost_usd']:.2f}")
    print(f"  Agents: {', '.join(session_metrics['agents_used'])}")
```

### Global Statistics

```python
from common.metrics_service import calculate_token_totals

totals = calculate_token_totals(all_delegations)

print(f"Total delegations: {totals['total_delegations']}")
print(f"Total tokens: {totals['total_tokens']:,}")
print(f"Total cost: ${totals['total_cost_usd']:.2f}")
print(f"Global amplification: {totals['global_amplification_ratio']:.2f}x")
print(f"Cache efficiency: {totals['global_cache_efficiency']:.2%}")
```

## Field Reference

### Token Fields

- `input_tokens` - Tokens sent to model (prompt)
- `output_tokens` - Tokens generated by model (response)
- `cache_read_tokens` - Cached tokens read (saves cost)
- `cache_write_tokens` - Tokens written to cache
- `total_tokens` - Sum of input + output

### Ratio Fields

- `amplification_ratio` - Output divided by input (output/input)
  - Higher is better (more output per input)
  - Typical range: 1-200x

- `cache_hit_rate` - Cache reads divided by input (cache_read/input)
  - Higher is better (more cache usage)
  - Range: 0-1 (can exceed 1 if cache > input)

### Cost Fields

- `cost_usd` - Total cost in US dollars
  - Based on Anthropic pricing (see PRICING_PER_1M)
  - Includes all token types

### Metadata Fields

- `agent_type` - Agent that handled delegation (str or None)
- `timestamp` - ISO timestamp of delegation (str or None)

## Pricing Information

Current pricing (Claude 3.5 Sonnet):

```python
from common.metrics_service import PRICING_PER_1M

# Per 1M tokens:
PRICING_PER_1M = {
    'input_tokens': 3.00,      # $3/1M
    'output_tokens': 15.00,    # $15/1M
    'cache_write': 3.75,       # $3.75/1M
    'cache_read': 0.30         # $0.30/1M
}
```

## Metric Definitions

```python
from common.metrics_service import METRIC_DEFINITIONS

for metric, definition in METRIC_DEFINITIONS.items():
    print(f"{metric}: {definition}")
```

Output:
```
input_tokens: Number of tokens sent to the model (prompt)
output_tokens: Number of tokens generated by the model (response)
cache_read_tokens: Number of cached tokens read (cost savings)
cache_write_tokens: Number of tokens written to cache
total_tokens: Sum of input and output tokens
amplification_ratio: Ratio of output to input tokens (output/input)
cache_hit_rate: Ratio of cache reads to input tokens (cache_read/input)
cost_usd: Cost in USD based on Anthropic pricing
```

## Data Format Compatibility

The service automatically handles these formats:

**Raw delegation** (from `delegation_raw.jsonl`):
```python
{
    'usage': {
        'input_tokens': 1000,
        'output_tokens': 2000,
        'cache_read_input_tokens': 500,
        'cache_creation_input_tokens': 100
    },
    'message': {
        'content': [...]
    }
}
```

**Enriched format** (from `enriched_sessions_v8.json`):
```python
{
    'agent_type': 'developer',
    'tokens_in': 1000,
    'tokens_out': 2000,
    'cache_read': 500
}
```

**Session format** (from `extract_all_sessions.py`):
```python
{
    'agent_type': 'backlog-manager',
    'input_tokens': 1000,
    'output_tokens': 2000,
    'cache_read_tokens': 500
}
```

All formats are normalized to the standard output format.

## Best Practices

1. **Always use the service** - Don't manually extract tokens
2. **Validate when needed** - Use `validate_metrics()` for critical operations
3. **Use type hints** - Import types for better IDE support
4. **Handle None values** - Agent type and timestamp can be None
5. **Check for zero** - Division by zero is handled, but check before complex calculations

## Migration Guide

**Old code**:
```python
usage = delegation.get('usage', {})
input_tokens = usage.get('input_tokens', 0)
output_tokens = usage.get('output_tokens', 0)
amplification = output_tokens / input_tokens if input_tokens > 0 else 0
```

**New code**:
```python
from common.metrics_service import extract_delegation_metrics

metrics = extract_delegation_metrics(delegation)
input_tokens = metrics['input_tokens']
output_tokens = metrics['output_tokens']
amplification = metrics['amplification_ratio']
```

Benefits:
- Handles missing fields
- Validates values
- Consistent across formats
- Single source of truth
