# Multi-Agent System Assessment

Analyze agent performance, delegation patterns, and system efficiency following **METHODOLOGIE-ANALYSE-RETROSPECTIVE.md**

---

## Parameters

**Scope**:
- Project(s): [project name | "all" | list]
- Period: [start-end date | "since start" | "september 2025"]

**Current system configuration** (optional):
- Active agents list
- Known recent modifications

---

## Execution

**Follow METHODOLOGIE-ANALYSE-RETROSPECTIVE.md completely:**

1. **Phase 0 (BLOCKING)**: Git archaeology + Data inventory + Assumptions sync
2. **Phase 1**: Enriched dataset extraction + classification
3. **Phase 2**: 4 parallel LLM agents + Python scripts + Cross-check
4. **Phase 3**: Current system assessment synthesis (80% focus) + User validation

**Output**: `observations-comparative-v[X].md` (agents/patterns/efficiency assessment)

---

## Scope Adaptations

**Single project**: Focus on current config, optional baseline
**Multi-projects**: Cross-project patterns, ROI by project type
**System comparison**: System A vs B (avoid temporal artifacts)

---

**Complete reference**: See `METHODOLOGIE-ANALYSE-RETROSPECTIVE.md`
